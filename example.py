#!/usr/bin/env python3
"""Example usage of Kotogram Japanese morphological analysis package"""

from kotogram import KotogramAnalyzer, RuleRegistry


def main():
    analyzer = KotogramAnalyzer()
    registry = RuleRegistry()
    registry.load_rules_from_directory("rules")

    examples = [
        "æœ€æ–°ã®ä¼ç”»æ›¸ãŒå‡ºæ¥ã‚ãŒã£ãŸã®ã§ã€ã©ã†ãã”è¦§ãã ã•ã„ã€‚",
        "å½¼ã¯è‡ªåˆ†ã¯ä½•ã‚‚ã—ã¦ã„ãªã„ä¸€æ–¹ã§ã€ä»–äººã®ã™ã‚‹ã“ã¨ã«ã‚ˆãæ–‡å¥ã‚’è¨€ã†ã€‚",
        "ã“ã®ç”ºã¯ä½ã¿ã‚ˆã„ã§ã™ã€‚",
        "å±±ç”°å…ˆç”Ÿã®è¬›æ¼”ã®é–“ã€çš†ç†±å¿ƒã«è©±ã‚’èã„ã¦ã„ãŸã€‚ç§ã¯å¤ä¼‘ã¿ã®é–“ã€ãšã£ã¨å®Ÿå®¶ã«ã„ã¾ã—ãŸã€‚",
        "ã“ã“æ•°å¹´ã€ã“ã®ç”ºã®äººå£ã¯æ¸›ã‚‹ä¸€æ–¹ã ã€‚ç§ãŒçš†æ§˜ã®ã”æ„è¦‹ã‚’ä¼ºã£ãŸä¸Šã§ã€æ¥é€±ã”å ±å‘Šã„ãŸã—ã¾ã™ã€‚",
    ]

    print("=== Japanese Grammar Pattern Matching Demo ===\n")

    for text in examples:
        print(f"ğŸ“ Sentence: {text}")

        # Analyze the sentence
        tokens = analyzer.parse_text(text)

        # Print tokens
        print("ğŸ” Tokens:")
        analyzer.print_tokens(tokens)

        # Find grammar patterns
        matches = registry.find_all_matches(tokens)

        if matches:
            print("ğŸ¯ Grammar patterns found:")
            for match_result in matches:
                print(f"   ğŸ“‹ Rule: {match_result.rule_name}")
                if match_result.description:
                    print(f"      Description: {match_result.description}")

                # Print each pattern match separately
                for i, pattern_match in enumerate(match_result.pattern_matches):
                    matched_text = " ".join(
                        [t.surface for t in pattern_match.matched_tokens]
                    )
                    print(
                        f"      Match {i + 1}: '{matched_text}' "
                        f"(pos {pattern_match.start_pos}-{pattern_match.end_pos})"
                    )

                    # Print individual tokens for this match
                    print(
                        f"         Tokens: {[t.surface for t in pattern_match.matched_tokens]}"
                    )
                print()
        else:
            print("âŒ No grammar patterns matched")

        print()


if __name__ == "__main__":
    main()
